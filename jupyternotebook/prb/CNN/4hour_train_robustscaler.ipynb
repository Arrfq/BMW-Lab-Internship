{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "# Parameter windowing\n",
    "input_width = 60*4\n",
    "label_width = 60\n",
    "shift = label_width\n",
    "total_window_size = input_width + shift\n",
    "OUT_STEPS = label_width\n",
    "# Definisikan irisan untuk input dan label\n",
    "input_slice = slice(0, input_width)\n",
    "label_start = total_window_size - label_width\n",
    "labels_slice = slice(label_start, None)\n",
    "train_df = None\n",
    "output_selected=['RRU.PrbUsedDl']\n",
    "train_name_cells=['S1/B2/C1']\n",
    "test_name_cells=['S7/B2/C1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  import_data(file_path=\"D:\\\\KULIAH\\\\teep\\\\AI\\\\dataset\\\\08_01_2024\\\\CellReports.csv\"):\n",
    "    \n",
    "    df_begin=pd.read_csv(file_path)\n",
    "    df_1=df_begin.copy()\n",
    "    convert_time=pd.to_datetime(df_1['timestamp'], unit='ms',origin='unix')\n",
    "    df_1.insert(df_1.columns.get_loc('timestamp') + 1, 'datetime_column', convert_time)\n",
    "    df_1.insert(df_1.columns.get_loc('datetime_column') + 2, 'hour', df_1['datetime_column'].dt.hour+df_1['datetime_column'].dt.minute/60)\n",
    "    df_1.set_index('datetime_column', inplace=True)\n",
    "    df_1.drop(columns=['timestamp'], inplace=True)\n",
    "    \n",
    "    # Find columns where correlation with 'RRU.PrbUsedDl'is greater than 0.5\n",
    "    columns_with_high_corr = ['RRU.PrbUsedDl','RRC.ConnMean', 'DRB.UEThpDl']\n",
    "    seleted_columns = ['Viavi.Cell.Name']+ columns_with_high_corr \n",
    "    df_2= df_1[seleted_columns].copy()\n",
    "    cell_name= test_name_cells+train_name_cells\n",
    "    df= df_2[df_2['Viavi.Cell.Name'].isin(cell_name)].copy()\n",
    "    \n",
    "    return df, cell_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data, train_df, isoutput=True, column_output=output_selected):\n",
    "    if isoutput:\n",
    "        median = train_df[column_output].median().values\n",
    "        q1 = train_df[column_output].quantile(0.25).values\n",
    "        q3 = train_df[column_output].quantile(0.75).values\n",
    "    else:\n",
    "        median = train_df.median().values\n",
    "        q1 = train_df.quantile(0.25).values\n",
    "        q3 = train_df.quantile(0.75).values\n",
    "\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Reshape for broadcasting with 2D matrix\n",
    "    median = median.reshape(1, -1)\n",
    "    iqr = iqr.reshape(1, -1)\n",
    "\n",
    "    return (data - median) / iqr\n",
    "\n",
    "def inverse_standardize_data(data, train_df, isoutput=True, column_output=output_selected):\n",
    "    if isoutput:\n",
    "        median = train_df[column_output].median().values\n",
    "        q1 = train_df[column_output].quantile(0.25).values\n",
    "        q3 = train_df[column_output].quantile(0.75).values\n",
    "    else:\n",
    "        median = train_df.median().values\n",
    "        q1 = train_df.quantile(0.25).values\n",
    "        q3 = train_df.quantile(0.75).values\n",
    "\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Reshape for broadcasting with 2D matrix\n",
    "    median = median.reshape(1, -1)\n",
    "    iqr = iqr.reshape(1, -1)\n",
    "\n",
    "    return data * iqr + median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(data_x,data_y, total_window_size, input_slice, labels_slice):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(len(data_x) - total_window_size + 1):\n",
    "        window_x = data_x[i:i+total_window_size]\n",
    "        x.append(window_x[input_slice])\n",
    "\n",
    "    for i in range(len(data_y) - total_window_size + 1):\n",
    "        window_y= data_y[i:i+total_window_size]\n",
    "        y.append(window_y[labels_slice])\n",
    "\n",
    "    return np.array(x), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(actual_df, predictions_df):\n",
    "    mae = mean_absolute_error(actual_df, predictions_df)\n",
    "    mse = mean_squared_error(actual_df, predictions_df)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mape = np.mean(np.abs((actual_df - predictions_df) / actual_df)) * 100\n",
    "    return mae, mape, mse, rmse\n",
    "\n",
    "def process_predictions(model, x_scaled, actual_df, input_width, label_width, columns):\n",
    "    predictions = model.predict(x_scaled[slice(None, None, label_width), :, :])\n",
    "    predictions_reshaped = predictions.reshape(-1, len(columns))\n",
    "    predictions_unscaled = inverse_standardize_data(predictions_reshaped, isoutput=True, train_df=train_df)\n",
    "    predictions_df = pd.DataFrame(predictions_unscaled, columns=columns, index=actual_df[input_width:].index)\n",
    "    return predictions_df\n",
    "def compute_error( x_scaled, actual_df, columns, model):\n",
    "    \n",
    "    # Process predictions for training and validation sets\n",
    "    predictions_df = process_predictions(model, x_scaled, actual_df, input_width, label_width, columns)\n",
    "\n",
    "    display(pd.concat((predictions_df.rename(columns={columns[0]: '%s_predict'%columns[0]}), actual_df[input_width:]), axis=1))\n",
    "    mae, mape, mse, rmse = compute_metrics(actual_df[input_width:], predictions_df)\n",
    "    \n",
    "    print(f\"MAE: {mae}, MAPE %: {mape}, MSE: {mse}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_predictions(val_df, x_val_scaled, model, val_scaled, input_width, label_width, num_features):\n",
    "    num_output = 2\n",
    "\n",
    "\n",
    "    # Predictions for validation data\n",
    "    val_predictions = model.predict(x_val_scaled[slice(None,None,label_width), :, :])\n",
    "    predictions_reshaped = val_predictions.reshape(-1, num_output)\n",
    "    predictions_unscaled = inverse_standardize_data(predictions_reshaped, isoutput=True, train_df=train_df)\n",
    "    val_predictions_df = pd.DataFrame(predictions_unscaled, columns=output_selected, index=val_df.index)\n",
    "\n",
    "    # Generate new predictions\n",
    "    val_new = val_scaled.tail(input_width).to_numpy()\n",
    "    val_new = val_new.reshape(1, -1, num_features)\n",
    "    generate_predictions = model.predict(val_new)\n",
    "    generate_predictions = inverse_standardize_data(generate_predictions.reshape(-1, num_output), isoutput=True, train_df=train_df)\n",
    "    generate_predictions_df = pd.DataFrame(generate_predictions, columns=output_selected, index=val_df.tail(label_width).index + pd.DateOffset(hours=1))\n",
    "\n",
    "    # Combine predictions\n",
    "    all_predictions = pd.concat([val_predictions_df, generate_predictions_df], axis=0)\n",
    "    inputs_graph = val_df[output_selected].iloc[-label_width * 3:-label_width]\n",
    "    labels_graph = val_df[output_selected].iloc[-label_width:]\n",
    "    predictions_graph = all_predictions.loc[labels_graph.index]\n",
    "    new_predictions_graph = all_predictions.loc[generate_predictions_df.index]\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for n, feature in enumerate(all_predictions.columns):\n",
    "        plt.subplot(len(all_predictions.columns), 1, n + 1)\n",
    "        plt.plot(inputs_graph.index, inputs_graph[feature], label='Inputs for orange', marker='.', zorder=-100, markersize=5)\n",
    "        plt.plot(labels_graph.index, labels_graph[feature], label='actual output for orange and inputs for red', marker='.', zorder=-100, c='#2ca02c')\n",
    "        plt.scatter(predictions_graph.index, predictions_graph[feature], marker='X', edgecolors='k', label='Prediction', c='#ff7f0e', s=int(32 * 1.5))\n",
    "        plt.scatter(new_predictions_graph.index, new_predictions_graph[feature], marker='+', label='New prediction', c='#FF012D', s=int(32 * 1.5))\n",
    "        plt.ylabel(feature)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.2, top=1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import time\n",
    "\n",
    "def tensorflow_cnn(X_train_scaled, Y_train_scaled, X_validation_scaled, Y_validation_scaled, \n",
    "                    learning_rate, target_error, max_epochs, max_sampel_batch,\n",
    "                    patience, save_best_model_path, validation_data=False, load_model=None, out_steps=OUT_STEPS):\n",
    "    global model\n",
    "\n",
    "    class MAEStopCallback(tf.keras.callbacks.Callback):\n",
    "        def __init__(self, threshold):\n",
    "            super(MAEStopCallback, self).__init__()\n",
    "            self.threshold = threshold\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if logs['mae'] < self.threshold:\n",
    "                print(f\"\\nMAE reached below {self.threshold}. Stopping training.\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "                \n",
    "    input_width = X_train_scaled.shape[1]\n",
    "    CONV_WIDTH = input_width # Define the width of the convolutional window\n",
    "    num_features = X_train_scaled.shape[2]\n",
    "    num_output = Y_train_scaled.shape[2]\n",
    "    out_steps = out_steps\n",
    "\n",
    "    model = tf.keras.models.Sequential()\n",
    "    if load_model is None:\n",
    "        model.add(tf.keras.layers.Lambda(lambda x: x[:, -CONV_WIDTH:, :], input_shape=(input_width, num_features)))\n",
    "        model.add(tf.keras.layers.Conv1D(120, activation='relu', kernel_size=int(CONV_WIDTH/8), padding='same'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv1D(120, activation='relu', kernel_size=int(CONV_WIDTH/4),padding='same') )\n",
    "        model.add(tf.keras.layers.Dropout(0.2))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Conv1D(120, activation='relu', kernel_size=int(CONV_WIDTH),padding='valid') )\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(out_steps * num_output, kernel_initializer=tf.initializers.zeros()))\n",
    "        model.add(tf.keras.layers.Reshape([out_steps, num_output]))\n",
    "\n",
    "    else:\n",
    "        print(\"Load model\")\n",
    "        model = tf.keras.models.load_model(load_model)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    mae_stop_callback = MAEStopCallback(threshold=target_error)\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        save_best_model_path,\n",
    "        monitor='val_loss',     \n",
    "        mode='min',         \n",
    "        save_best_only=True, \n",
    "        verbose=1            \n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStopping(\n",
    "        monitor='loss',     \n",
    "        mode='min',         \n",
    "        patience=patience,    \n",
    "        restore_best_weights=True,\n",
    "        verbose=1            \n",
    "    )\n",
    "\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=int(1), min_lr=0.00001, verbose=1)\n",
    "\n",
    "    time_start = time.time()\n",
    "    if validation_data:\n",
    "        model.fit(X_train_scaled, Y_train_scaled, epochs=max_epochs, batch_size=max_sampel_batch,  \n",
    "                  callbacks=[mae_stop_callback, checkpoint_callback, early_stopping_callback, reduce_lr], \n",
    "                  validation_data=(X_validation_scaled, Y_validation_scaled), validation_batch_size=max_sampel_batch)\n",
    "    else:\n",
    "        model.fit(X_train_scaled, Y_train_scaled, epochs=max_epochs, batch_size=max_sampel_batch, \n",
    "                  callbacks=[mae_stop_callback, checkpoint_callback, early_stopping_callback, reduce_lr])\n",
    "    \n",
    "    print(\"time computation seconds: \", time.time() - time_start)\n",
    "    \n",
    "    loss, MSE, MAE, RMSE, MAPE = model.evaluate(X_train_scaled, Y_train_scaled)\n",
    "    print(\"loss: \", loss, \"MSE: \", MSE, \"MAE: \", MAE, \"RMSE: \", RMSE, \"MAPE: \", MAPE)\n",
    "    \n",
    "    return model, loss, MSE, MAE, RMSE, MAPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_program(train_df,val_df, index_cell, name_file, name_file_before):\n",
    "    \n",
    "    train_scaled = standardize_data(train_df, isoutput=False, train_df=train_df)\n",
    "    val_scaled= standardize_data(val_df, isoutput=False, train_df=train_df)\n",
    "    # Membuat windowed dataset untuk set pelatihan, validasi, dan pengujian\n",
    "\n",
    "    x_train_scaled, y_train_scaled = make_windows(train_scaled.to_numpy(), train_scaled[output_selected].to_numpy(),total_window_size, input_slice, labels_slice)\n",
    "    x_val_scaled, y_val_scaled = make_windows(val_scaled.to_numpy(), val_scaled[output_selected].to_numpy(),total_window_size, input_slice, labels_slice)\n",
    "    print(x_train_scaled.shape, y_train_scaled.shape)\n",
    "    if index_cell==0:\n",
    "        model, loss, MSE, MAE, RMSE,  MAPE  = tensorflow_cnn(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled,\n",
    "                                                        learning_rate=0.005, target_error=0.001,  max_epochs=20, max_sampel_batch=int(input_width/2), \n",
    "                                                        patience=6,  save_best_model_path = name_file, \n",
    "                                                        validation_data=True, load_model=\"testaja.hdf5\", out_steps=OUT_STEPS)\n",
    "        model.summary()\n",
    "        model.save(\"testaja_part2.hdf5\")\n",
    "    else:\n",
    "        model, loss, MSE, MAE, RMSE,  MAPE  = tensorflow_cnn(x_train_scaled, y_train_scaled, x_val_scaled, y_val_scaled,\n",
    "                                                        learning_rate=0.0001, target_error=0.001,  max_epochs=10, max_sampel_batch=int(input_width/2), \n",
    "                                                        patience=6,  save_best_model_path = name_file, \n",
    "                                                        validation_data=True, load_model=name_file_before, out_steps=OUT_STEPS)\n",
    "\n",
    "    model = tf.keras.models.load_model('%s'%name_file)\n",
    "    columns = output_selected\n",
    "    output_actual_train = train_df[columns]\n",
    "    output_actual_val = val_df[columns]\n",
    "    print(\"Training Metrics:\")\n",
    "    compute_error(x_train_scaled,  output_actual_train,columns, model)\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    compute_error(x_val_scaled,  output_actual_val,columns, model)\n",
    "    #print(\"Training Plot:\")\n",
    "    #plot_predictions( output_actual_train[input_width:], x_train_scaled, model, train_scaled, input_width, label_width, num_features)\n",
    "    #print(\"\\nValidation (test) Plot:\")\n",
    "    #plot_predictions( output_actual_val[input_width:], x_val_scaled, model, val_scaled, input_width, label_width, num_features)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "name_file:  4hour_cnn0802_testajapart2_1.hdf5\n",
      "name_file_before:  4hour_cnn0802_testajapart2_0.hdf5\n",
      "Cell Name:  S7/B2/C1\n",
      "(11221, 240, 3) (11221, 60, 1)\n",
      "Load model\n",
      "Epoch 1/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.1539 - mse: 0.1539 - mae: 0.3113 - mape: 91479.9766 - rmse: 0.3923\n",
      "Epoch 1: val_loss improved from inf to 0.59397, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 9s 62ms/step - loss: 0.1539 - mse: 0.1539 - mae: 0.3113 - mape: 91479.9766 - rmse: 0.3923 - val_loss: 0.5940 - val_mse: 0.5940 - val_mae: 0.6346 - val_mape: 81506.4219 - val_rmse: 0.7707 - lr: 0.0050\n",
      "Epoch 2/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1371 - mse: 0.1371 - mae: 0.2935 - mape: 84890.6250 - rmse: 0.3703\n",
      "Epoch 2: val_loss improved from 0.59397 to 0.59284, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 5s 56ms/step - loss: 0.1371 - mse: 0.1371 - mae: 0.2934 - mape: 85293.1797 - rmse: 0.3703 - val_loss: 0.5928 - val_mse: 0.5928 - val_mae: 0.6360 - val_mape: 79821.0469 - val_rmse: 0.7700 - lr: 0.0050\n",
      "Epoch 3/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1259 - mse: 0.1259 - mae: 0.2810 - mape: 72849.5859 - rmse: 0.3549\n",
      "Epoch 3: val_loss improved from 0.59284 to 0.56372, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 5s 58ms/step - loss: 0.1259 - mse: 0.1259 - mae: 0.2811 - mape: 72561.6484 - rmse: 0.3549 - val_loss: 0.5637 - val_mse: 0.5637 - val_mae: 0.6172 - val_mape: 73529.6016 - val_rmse: 0.7508 - lr: 0.0050\n",
      "Epoch 4/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1187 - mse: 0.1187 - mae: 0.2725 - mape: 72846.8828 - rmse: 0.3446\n",
      "Epoch 4: val_loss did not improve from 0.56372\n",
      "94/94 [==============================] - 6s 59ms/step - loss: 0.1187 - mse: 0.1187 - mae: 0.2725 - mape: 72451.9766 - rmse: 0.3446 - val_loss: 0.6090 - val_mse: 0.6090 - val_mae: 0.6446 - val_mape: 65233.1172 - val_rmse: 0.7804 - lr: 0.0050\n",
      "Epoch 5/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1092 - mse: 0.1092 - mae: 0.2608 - mape: 67038.6172 - rmse: 0.3305\n",
      "Epoch 5: val_loss improved from 0.56372 to 0.55660, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 6s 62ms/step - loss: 0.1092 - mse: 0.1092 - mae: 0.2608 - mape: 66675.4766 - rmse: 0.3305 - val_loss: 0.5566 - val_mse: 0.5566 - val_mae: 0.6139 - val_mape: 62848.0977 - val_rmse: 0.7461 - lr: 0.0050\n",
      "Epoch 6/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.1044 - mse: 0.1044 - mae: 0.2548 - mape: 76861.4297 - rmse: 0.3231\n",
      "Epoch 6: val_loss improved from 0.55660 to 0.52126, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 6s 65ms/step - loss: 0.1044 - mse: 0.1044 - mae: 0.2547 - mape: 76444.6562 - rmse: 0.3231 - val_loss: 0.5213 - val_mse: 0.5213 - val_mae: 0.6004 - val_mape: 51100.5977 - val_rmse: 0.7220 - lr: 0.0050\n",
      "Epoch 7/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0986 - mse: 0.0986 - mae: 0.2475 - mape: 84293.9766 - rmse: 0.3140\n",
      "Epoch 7: val_loss did not improve from 0.52126\n",
      "94/94 [==============================] - 6s 67ms/step - loss: 0.0986 - mse: 0.0986 - mae: 0.2475 - mape: 84293.9766 - rmse: 0.3140 - val_loss: 0.6154 - val_mse: 0.6154 - val_mae: 0.6597 - val_mape: 39705.7656 - val_rmse: 0.7845 - lr: 0.0050\n",
      "Epoch 8/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0906 - mse: 0.0906 - mae: 0.2374 - mape: 90778.0000 - rmse: 0.3010\n",
      "Epoch 8: val_loss did not improve from 0.52126\n",
      "94/94 [==============================] - 6s 68ms/step - loss: 0.0906 - mse: 0.0906 - mae: 0.2374 - mape: 90778.0000 - rmse: 0.3010 - val_loss: 0.5642 - val_mse: 0.5642 - val_mae: 0.6226 - val_mape: 49313.3281 - val_rmse: 0.7511 - lr: 0.0050\n",
      "Epoch 9/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0798 - mse: 0.0798 - mae: 0.2231 - mape: 85424.2031 - rmse: 0.2825\n",
      "Epoch 9: val_loss did not improve from 0.52126\n",
      "94/94 [==============================] - 7s 69ms/step - loss: 0.0798 - mse: 0.0798 - mae: 0.2231 - mape: 85786.3438 - rmse: 0.2824 - val_loss: 0.5502 - val_mse: 0.5502 - val_mae: 0.6203 - val_mape: 45058.9492 - val_rmse: 0.7417 - lr: 0.0050\n",
      "Epoch 10/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0626 - mse: 0.0626 - mae: 0.1978 - mape: 73097.5156 - rmse: 0.2503\n",
      "Epoch 10: val_loss did not improve from 0.52126\n",
      "94/94 [==============================] - 7s 72ms/step - loss: 0.0626 - mse: 0.0626 - mae: 0.1978 - mape: 73279.3516 - rmse: 0.2502 - val_loss: 0.6359 - val_mse: 0.6359 - val_mae: 0.6738 - val_mape: 39249.6211 - val_rmse: 0.7974 - lr: 0.0050\n",
      "Epoch 11/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0397 - mse: 0.0397 - mae: 0.1577 - mape: 66050.3359 - rmse: 0.1993\n",
      "Epoch 11: val_loss did not improve from 0.52126\n",
      "94/94 [==============================] - 7s 71ms/step - loss: 0.0397 - mse: 0.0397 - mae: 0.1578 - mape: 65900.3906 - rmse: 0.1994 - val_loss: 0.6061 - val_mse: 0.6061 - val_mae: 0.6513 - val_mape: 50720.7969 - val_rmse: 0.7785 - lr: 0.0050\n",
      "Epoch 12/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0270 - mse: 0.0270 - mae: 0.1304 - mape: 57065.3906 - rmse: 0.1642\n",
      "Epoch 12: val_loss improved from 0.52126 to 0.51488, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 7s 74ms/step - loss: 0.0270 - mse: 0.0270 - mae: 0.1305 - mape: 56765.8828 - rmse: 0.1643 - val_loss: 0.5149 - val_mse: 0.5149 - val_mae: 0.5921 - val_mape: 84407.0312 - val_rmse: 0.7176 - lr: 0.0050\n",
      "Epoch 13/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0231 - mse: 0.0231 - mae: 0.1207 - mape: 51662.3906 - rmse: 0.1519\n",
      "Epoch 13: val_loss did not improve from 0.51488\n",
      "94/94 [==============================] - 7s 73ms/step - loss: 0.0231 - mse: 0.0231 - mae: 0.1207 - mape: 51662.3906 - rmse: 0.1519 - val_loss: 0.6002 - val_mse: 0.6002 - val_mae: 0.6529 - val_mape: 66840.5469 - val_rmse: 0.7747 - lr: 0.0050\n",
      "Epoch 14/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0216 - mse: 0.0216 - mae: 0.1168 - mape: 50667.0195 - rmse: 0.1471\n",
      "Epoch 14: val_loss improved from 0.51488 to 0.47710, saving model to 4hour_cnn0802_testajapart2_1.hdf5\n",
      "94/94 [==============================] - 7s 76ms/step - loss: 0.0216 - mse: 0.0216 - mae: 0.1168 - mape: 51311.2422 - rmse: 0.1471 - val_loss: 0.4771 - val_mse: 0.4771 - val_mae: 0.5732 - val_mape: 63925.6289 - val_rmse: 0.6907 - lr: 0.0050\n",
      "Epoch 15/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0206 - mse: 0.0206 - mae: 0.1140 - mape: 46843.9492 - rmse: 0.1435\n",
      "Epoch 15: val_loss did not improve from 0.47710\n",
      "94/94 [==============================] - 7s 76ms/step - loss: 0.0206 - mse: 0.0206 - mae: 0.1141 - mape: 47617.6641 - rmse: 0.1436 - val_loss: 0.5683 - val_mse: 0.5683 - val_mae: 0.6344 - val_mape: 71614.3828 - val_rmse: 0.7539 - lr: 0.0050\n",
      "Epoch 16/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0200 - mse: 0.0200 - mae: 0.1124 - mape: 52338.9688 - rmse: 0.1415\n",
      "Epoch 16: val_loss did not improve from 0.47710\n",
      "94/94 [==============================] - 7s 75ms/step - loss: 0.0200 - mse: 0.0200 - mae: 0.1125 - mape: 52123.1953 - rmse: 0.1415 - val_loss: 0.5855 - val_mse: 0.5855 - val_mae: 0.6465 - val_mape: 61069.8359 - val_rmse: 0.7652 - lr: 0.0050\n",
      "Epoch 17/20\n",
      "94/94 [==============================] - ETA: 0s - loss: 0.0186 - mse: 0.0186 - mae: 0.1084 - mape: 46587.0664 - rmse: 0.1364\n",
      "Epoch 17: val_loss did not improve from 0.47710\n",
      "94/94 [==============================] - 7s 77ms/step - loss: 0.0186 - mse: 0.0186 - mae: 0.1084 - mape: 46587.0664 - rmse: 0.1364 - val_loss: 0.5169 - val_mse: 0.5169 - val_mae: 0.6025 - val_mape: 72255.4531 - val_rmse: 0.7190 - lr: 0.0050\n",
      "Epoch 18/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0184 - mse: 0.0184 - mae: 0.1079 - mape: 45414.4414 - rmse: 0.1356\n",
      "Epoch 18: val_loss did not improve from 0.47710\n",
      "94/94 [==============================] - 7s 79ms/step - loss: 0.0184 - mse: 0.0184 - mae: 0.1079 - mape: 45966.0859 - rmse: 0.1357 - val_loss: 0.5289 - val_mse: 0.5289 - val_mae: 0.6108 - val_mape: 68828.1797 - val_rmse: 0.7273 - lr: 0.0050\n",
      "Epoch 19/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0185 - mse: 0.0185 - mae: 0.1081 - mape: 48239.4219 - rmse: 0.1359\n",
      "Epoch 19: val_loss did not improve from 0.47710\n",
      "\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0004999999888241291.\n",
      "94/94 [==============================] - 8s 82ms/step - loss: 0.0185 - mse: 0.0185 - mae: 0.1081 - mape: 48268.5352 - rmse: 0.1360 - val_loss: 0.5122 - val_mse: 0.5122 - val_mae: 0.5984 - val_mape: 72310.4766 - val_rmse: 0.7157 - lr: 0.0050\n",
      "Epoch 20/20\n",
      "93/94 [============================>.] - ETA: 0s - loss: 0.0161 - mse: 0.0161 - mae: 0.1007 - mape: 45484.8242 - rmse: 0.1268\n",
      "Epoch 20: val_loss did not improve from 0.47710\n",
      "94/94 [==============================] - 8s 84ms/step - loss: 0.0161 - mse: 0.0161 - mae: 0.1008 - mape: 45464.6133 - rmse: 0.1269 - val_loss: 0.5188 - val_mse: 0.5188 - val_mae: 0.6085 - val_mape: 57919.9375 - val_rmse: 0.7203 - lr: 5.0000e-04\n",
      "time computation seconds:  135.3585045337677\n",
      "351/351 [==============================] - 3s 10ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0385 - mape: 17228.2344 - rmse: 0.0486\n",
      "loss:  0.0023624850437045097 MSE:  0.0023624852765351534 MAE:  0.03854517638683319 RMSE:  17228.234375 MAPE:  0.048605404794216156\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 240, 3)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 240, 120)          10920     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 240, 120)         480       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 240, 120)          864120    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 240, 120)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 240, 120)         480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1, 120)            3456120   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 120)           480       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1, 60)             7260      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 60, 1)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,339,860\n",
      "Trainable params: 4,339,140\n",
      "Non-trainable params: 720\n",
      "_________________________________________________________________\n",
      "Training Metrics:\n",
      "6/6 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRU.PrbUsedDl_predict</th>\n",
       "      <th>RRU.PrbUsedDl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:00:00</th>\n",
       "      <td>14.537268</td>\n",
       "      <td>14.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:01:00</th>\n",
       "      <td>42.449425</td>\n",
       "      <td>53.983333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:02:00</th>\n",
       "      <td>14.217965</td>\n",
       "      <td>17.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:03:00</th>\n",
       "      <td>22.751361</td>\n",
       "      <td>17.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:04:00</th>\n",
       "      <td>40.528892</td>\n",
       "      <td>47.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:55:00</th>\n",
       "      <td>24.632424</td>\n",
       "      <td>25.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:56:00</th>\n",
       "      <td>30.655791</td>\n",
       "      <td>24.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:57:00</th>\n",
       "      <td>52.482366</td>\n",
       "      <td>59.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:58:00</th>\n",
       "      <td>13.610628</td>\n",
       "      <td>6.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:59:00</th>\n",
       "      <td>7.915385</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RRU.PrbUsedDl_predict  RRU.PrbUsedDl\n",
       "datetime_column                                          \n",
       "2024-08-01 04:00:00              14.537268      14.966667\n",
       "2024-08-01 04:01:00              42.449425      53.983333\n",
       "2024-08-01 04:02:00              14.217965      17.550000\n",
       "2024-08-01 04:03:00              22.751361      17.533333\n",
       "2024-08-01 04:04:00              40.528892      47.766667\n",
       "...                                    ...            ...\n",
       "2024-08-08 23:55:00              24.632424      25.116667\n",
       "2024-08-08 23:56:00              30.655791      24.666667\n",
       "2024-08-08 23:57:00              52.482366      59.133333\n",
       "2024-08-08 23:58:00              13.610628       6.583333\n",
       "2024-08-08 23:59:00               7.915385       5.000000\n",
       "\n",
       "[11280 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 2.4363772769447745, MAPE %: inf, MSE: 9.382794276866226, RMSE: 3.063134714123136\n",
      "\n",
      "Validation Metrics:\n",
      "6/6 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RRU.PrbUsedDl_predict</th>\n",
       "      <th>RRU.PrbUsedDl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:00:00</th>\n",
       "      <td>34.344923</td>\n",
       "      <td>1.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:01:00</th>\n",
       "      <td>23.095740</td>\n",
       "      <td>8.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:02:00</th>\n",
       "      <td>40.274228</td>\n",
       "      <td>6.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:03:00</th>\n",
       "      <td>32.888792</td>\n",
       "      <td>14.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-01 04:04:00</th>\n",
       "      <td>34.089730</td>\n",
       "      <td>4.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:55:00</th>\n",
       "      <td>19.902885</td>\n",
       "      <td>59.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:56:00</th>\n",
       "      <td>18.725217</td>\n",
       "      <td>37.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:57:00</th>\n",
       "      <td>33.136024</td>\n",
       "      <td>12.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:58:00</th>\n",
       "      <td>35.823708</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-08-08 23:59:00</th>\n",
       "      <td>27.907007</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11280 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RRU.PrbUsedDl_predict  RRU.PrbUsedDl\n",
       "datetime_column                                          \n",
       "2024-08-01 04:00:00              34.344923       1.766667\n",
       "2024-08-01 04:01:00              23.095740       8.266667\n",
       "2024-08-01 04:02:00              40.274228       6.433333\n",
       "2024-08-01 04:03:00              32.888792      14.766667\n",
       "2024-08-01 04:04:00              34.089730       4.016667\n",
       "...                                    ...            ...\n",
       "2024-08-08 23:55:00              19.902885      59.733333\n",
       "2024-08-08 23:56:00              18.725217      37.333333\n",
       "2024-08-08 23:57:00              33.136024      12.033333\n",
       "2024-08-08 23:58:00              35.823708       3.000000\n",
       "2024-08-08 23:59:00              27.907007       3.000000\n",
       "\n",
       "[11280 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 18.588708065649747, MAPE %: inf, MSE: 500.73597957483867, RMSE: 22.377130727035553\n"
     ]
    }
   ],
   "source": [
    "df_start, cell_name= import_data(\"D:\\\\KULIAH\\\\teep\\\\AI\\\\dataset\\\\08_01_2024\\\\CellReports.csv\")\n",
    "#now = datetime.datetime.now()\n",
    "timestamp = \"cnn0802_testajapart2\"\n",
    "for index in range(0,1):\n",
    "    print(index)\n",
    "\n",
    "    train_df = df_start[df_start['Viavi.Cell.Name'] == train_name_cells[index]]\n",
    "    train_df = train_df.loc[~train_df.index.duplicated()]\n",
    "    train_df=train_df.drop(columns=['Viavi.Cell.Name']).astype(float).copy()\n",
    "\n",
    "    val_df= df_start[df_start['Viavi.Cell.Name'] == test_name_cells[0]]\n",
    "    val_df=val_df.loc[~val_df.index.duplicated()]\n",
    "    val_df=val_df.drop(columns=['Viavi.Cell.Name']).astype(float).copy()\n",
    "\n",
    "    name_file='4hour_%s_%s.hdf5'%(timestamp, index+1)\n",
    "    name_file_before='4hour_%s_%s.hdf5'%(timestamp, index)\n",
    "    print(\"name_file: \", name_file)\n",
    "    print(\"name_file_before: \", name_file_before)\n",
    "    print(\"Cell Name: \", cell_name[index])\n",
    "    #display(train_df)\n",
    "    running_program(train_df=train_df, val_df=val_df, index_cell=index, name_file=name_file, name_file_before=name_file_before)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
