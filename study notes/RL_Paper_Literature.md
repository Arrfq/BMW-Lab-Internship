# [Efficient End-Edge-Cloud Task Offloading in 6G Networks Based on Multi-Agent Deep Reinforcement Learning](https://ieeexplore.ieee.org/document/9218920)

| item | information |
| --- | --- |
| Authors |Hao She ; Lixing Yan ;Yongan Guo|
| Date of Publication | 20 March 2024 |
|type |IEEE Internet of Things Journal|
| total pages |  12 pages|
| keywords |End-Edge-Cloud, task offloading, 6G, multiagentdeep reinforcement learning|
## About & Contributor of the Paper
- Task offloading optimizes distributed systems by splitting tasks among network devices to reduce individual device workload.
- This paper design an efficient algorithm based on multi-agent deep depolicy gradient (MADDPG) to observe the states of user equipments (UEs), edge servers, and cloud server thereby reducing offloading delay and energy consumption. 
## Model & Problem
-![image](https://github.com/bmw-ece-ntust/internship/assets/87467666/9a9000a5-2b08-48f0-b4c6-a117d788ead1)
    $$\text{Figure Task Offloading Model in 6G}$$ 
- If a task cannot be completed locally, the user end offloads it to edge or cloud servers based on the chosen strategy. The network consists of *U* (user ends), *E* (edge servers), and *C* (cloud servers).
-  The issue of resource allocation in 6G networks is typically focused on two key factors: total time and total energy. 
##  Evaluation Performance


 
